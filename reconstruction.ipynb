{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105852c6-c74c-42a8-912d-0babab4bdac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd418b07-2854-4650-a14a-704c90fb2029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reconstruction import Model, TopKLayer\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import synthesizer\n",
    "import os\n",
    "import itertools\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db09175a-96d7-476c-bce5-629c3a8f6b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a1f667-2498-4434-a0ac-f06012f843b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(img_path, p, epochs=100):\n",
    "    m = Model(img_path, topk=p['topk'], device=p['device'], dimensions=p['dimensions'], mode=p['mode'])\n",
    "    I = torch.rand((1, 3, m.dimensions[0], m.dimensions[1])).to(device)\n",
    "    I = I.requires_grad_(True)\n",
    "    optimizer = optim.LBFGS([I], lr=1)\n",
    "\n",
    "    r = 0\n",
    "    while r < epochs:\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            I.grad = None\n",
    "            m(I)\n",
    "            loss = m.loss()\n",
    "            loss.backward(retain_graph=True)\n",
    "            #print(f'I gradient: {I.grad}')\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        r += 1\n",
    "        print(f'\\rEpoch {r}: Loss {m.loss().item()}', end='')\n",
    "    print()\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0091b4d0-53bd-47e0-bf97-b7550e7f1da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(img_name):\n",
    "    img_ext = '.jpg'\n",
    "    img_path = os.path.join('./', img_name + img_ext)\n",
    "    return img_path, img_name, img_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25372787-3ec3-4379-a203-5601ff963b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'topk': 0.05,\n",
    "    'device': device,\n",
    "    'dimensions': (500, 500), \n",
    "    'mode': 'topk'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cccb064c-ec96-4332-81ff-c44918f5fa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5, 'topk', 'jeep1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrontio/uni/differentiable/labs/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss 84011.8046875\n",
      "(0.5, 'topk', 'rocks')\n",
      "Epoch 100: Loss 85615.4062555\n",
      "(0.5, 'non-topk', 'jeep1')\n",
      "Epoch 100: Loss 831537.0625\n",
      "(0.5, 'non-topk', 'rocks')\n",
      "Epoch 100: Loss 905298.9375\n",
      "(0.5, 'both', 'jeep1')\n",
      "Epoch 100: Loss 113.34915924072266\n",
      "(0.5, 'both', 'rocks')\n",
      "Epoch 100: Loss 0.6456871628761292\n",
      "(0.95, 'topk', 'jeep1')\n",
      "Epoch 100: Loss 804.5863647460938\n",
      "(0.95, 'topk', 'rocks')\n",
      "Epoch 100: Loss 4727.38330078125\n",
      "(0.95, 'non-topk', 'jeep1')\n",
      "Epoch 100: Loss 78486.515625\n",
      "(0.95, 'non-topk', 'rocks')\n",
      "Epoch 100: Loss 82117.890625\n",
      "(0.95, 'both', 'jeep1')\n",
      "Epoch 100: Loss 241.20191955566406\n",
      "(0.95, 'both', 'rocks')\n",
      "Epoch 100: Loss 0.6387669444084167\n"
     ]
    }
   ],
   "source": [
    "topks = [0.05, 0.5, 0.95]\n",
    "modes = ['topk', 'non-topk', 'both']\n",
    "img_names = ['jeep1', 'rocks']\n",
    "\n",
    "for p in itertools.product(topks, modes, img_names):\n",
    "    print(p)\n",
    "    topk = p[0]\n",
    "    mode = p[1]\n",
    "    img_path, img_name, img_ext = get_path(p[2])\n",
    "    \n",
    "    parameters['topk'] = topk\n",
    "    parameters['mode'] = mode\n",
    "\n",
    "    I = getImage(img_path, parameters, epochs=100)\n",
    "    transforms.ToPILImage()(np.clip(I.clone().detach().cpu().squeeze(0).numpy().transpose(1, 2, 0), 0, 1)).save(os.path.join('./results', f'{img_name}-{topk}-{mode}{img_ext}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ef5e1-b3b1-4285-b98d-eb5c99300049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
